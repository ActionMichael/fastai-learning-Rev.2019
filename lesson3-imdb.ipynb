{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP自然語言處理這次不是分類圖片，而是分類文檔。\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#不再是引用fastai.vision，這次我們引用fastai.text。這裡面你可以找到所有的專門用來分析文本文檔的東西。\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"這個例子裡，我們要用一個叫IMDB的數據集。 IMDB裡有很多電影評論。一般是兩三千個單詞。每個評論被分為正面的或者負面的。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://files.fast.ai/data/examples/imdb_sample\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/User/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only contains one csv file, let's have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"我們可以使用pandas.read來讀取csv文件\"\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"內容如下\"\n",
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"我們可以使用factory methods或者data block API來創建data bunch。這是一個從CSV文本文件中創建data bunch的快速方法。\"\n",
    "data_lm = TextDataBunch.from_csv(path, 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
    "\n",
    "Before we delve into the explanations, let's take the time to save the things that were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"分詞（Tokenization）: 它處理這些單詞，把它們轉成標準的token（分詞）。基本上每個token代表一個單詞。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of processing we make the texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
    "\n",
    "- we need to take care of punctuation\n",
    "- some words are contractions of two different words, like isn't or don't\n",
    "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
    "\n",
    "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n  xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , steaming bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj sydney , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n  xxmaj it 's usually satisfying to watch a film director change his style /</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this film sat on my xxmaj tivo for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj yorkers . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i really wanted to love this show . i truly , honestly did . \\n \\n  xxmaj for the first time , gay viewers get their own version of the \" xxmaj the xxmaj bachelor \" . xxmaj with the help of his obligatory \" hag \" xxmaj xxunk , xxmaj james , a good looking , well - to - do thirty - something has the chance</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos \\n \\n  i 'm sure things did n't exactly go the same way in the real life of xxmaj homer xxmaj hickam as they did in the film adaptation of his book , xxmaj rocket xxmaj boys , but the movie \" xxmaj october xxmaj sky \" ( an xxunk of the book 's title ) is good enough to stand alone . i have not read xxmaj</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"它做了一些這樣的事情，看到沒有，“didn't” 被轉成裡兩個獨立的單詞（did 和 n't）。並且所有的內容都被轉成小寫了。\n",
    "   看到“you're”被轉成兩個獨立的單詞（you 和're）了嗎? 分詞（Tokenization）是要讓每個“token”（每個詞兩邊都有空白）代表一個獨立的語義。\n",
    "   它遇到特別少見的單詞（比如說名字）時，會把它們用一個叫unknown （xxunk）專門的token替代。在fastai裡所有以 xx 開頭的都是特殊token。\n",
    "   這就是Tokenization，所以我們最後可以得到一個被分詞過的單詞的列表。你也能看到標點周圍也被加了空格，來保證它們是單獨的token。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like this: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"編號（Numericalization）\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"下一步是為所有可能的token創建一個完整的唯一的列表，這被叫做vocab單詞表。\n",
    "    data.vocab.itos[:10]\n",
    "    ['xxunk', 'xxpad', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n",
    "    這是所有電影評論裡最常出現的token（前十個）。然後我們用一個數字列表來替代每個電影評論。\n",
    "    data.train_ds[0][0].data[:10]\n",
    "    array([ 43, 44, 40, 34, 171, 62, 6, 352, 3, 47])\n",
    "    這個列表裡的數字代表這個位置上的分詞在單詞表裡的序號。\n",
    "    \n",
    "    @分詞（Tokenization）和編號（Numericalization），是NLP裡把文檔轉成一個數字list的標準方式。@\n",
    "\"\"\"\n",
    "data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos xxmaj want to watch a scary horror film ? xxmaj then steer clear of this one . xxmaj there 's not enough beer in the world to make this film enjoyable . \n",
       " \n",
       "  xxmaj however , there is enough scotch . xxmaj single - xxunk , if you can manage it . \n",
       " \n",
       "  xxmaj if the previous comments were n't enough to keep you from watching this film sober , allow me to assist . xxup nasa sends one man and two xxunk extras into space to orbit xxmaj saturn . a really big xxunk xxunk causes xxmaj colonel xxmaj steve xxmaj west to bleed from the nose . xxmaj things go downhill from there , and wackiness ensues . \n",
       " \n",
       "  i actually read the book adaptation , which was published and released only in the xxup uk . xxup miles better than the film , and the book was dreadful . xxmaj at least some pretense is made towards suspense , and some sort of explanation of events is pulled out from the author 's ( xxunk with ' gas ' ) . \n",
       " \n",
       "  xxmaj not to say that the film is completely without merit . xxmaj rick xxmaj baker learned that he really ought to read a contract before xxunk on to a film , and xxmaj jonathan xxmaj demme found that he 's really better suited to direct . \n",
       " \n",
       "  xxmaj yes , there is an xxup mst3 k episode featuring this flick , but it is , of course , edited quite a bit . xxmaj without the obligatory flashing of the breasts , not even the healing power of scotch can save you . \n",
       " \n",
       "  xxmaj please , just go watch xxmaj raiders of the xxmaj lost xxmaj ark if you want to see a guy melt . xxmaj see xxmaj space xxmaj xxunk if you feel the need to see xxunk . i can not , in all good conscience , recommend this film to the sober film - going public ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   5, 196,  15, 126,  13, 673, 206,  32,  67], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data block API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
    "\n",
    "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the various arguments to pass will appear in the step they're revelant, so it'll be more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"我們用data block API:\n",
    "   這次，不再用ImageFilesList，而是從CSV創建一個TextList，創建一個data bunch。這時我們可以開始創建一個模型了。\n",
    "\"\"\"\n",
    "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"做NLP分類時我們會創建兩個模型：\n",
    "   第一個模型叫 語言模型（language model）(第14行~33行)我們用普通的方式訓練\n",
    "   (第21行)learn = language_model_learner(data_lm,pretrained_model=URLs.WT103, drop_mult=0.3)\n",
    "   我們創建一個language model learner，訓練它，保存它，解凍，再訓練。\n",
    "   \n",
    "   在我們創建語言模型之後，我們創建分類器（classifier）(第34行~56行)。\n",
    "   我們創建classifier的data bunch，創建一個 learner，訓練它，得到準確率。\n",
    "   \n",
    "   這裡快速講下。下週我們會講更多細節。你可以看到訓練NLP分類器的基本思路和我們之前的創建其他模型的思路是很相似的。\n",
    "   目前IMDB分類的最好成績（state of the art）是我們和一個叫Sebastian Ruder的同事一起創造、發表的。\n",
    "   剛剛演示的基本就是取得最好成績的算法，裡面還有些其它的小技巧。如果你努力嘗試，你可以達到95%。這很接近我們得到的最好成績。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab the full dataset for what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new version of the dataset is available.\n",
      "Downloading https://s3.amazonaws.com/fast-ai-nlp/imdb\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/User/.fastai/data/imdb/imdb.vocab'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/README'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/test'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/tmp_clas'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/tmp_lm'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/train'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/unsup')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/User/.fastai/data/imdb/train/labeledBow.feat'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/train/neg'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/train/pos'),\n",
       " WindowsPath('C:/Users/User/.fastai/data/imdb/train/unsupBow.feat')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
    "\n",
    "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipedia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word is, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust the parameters of our model by a little bit. Plus there might be some words that would be extremely common in the reviews dataset but would be barely present in wikipedia, and therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_folder(path)\n",
    "           #Inputs: all the text files in path\n",
    "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "            .split_by_rand_pct(0.1)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs))\n",
    "data_lm.save('data_lm.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
    "\n",
    "The line before being a bit long, we want to load quickly the final ids by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(path, 'data_lm.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>later , by which time i did not care . xxmaj the character we should really care about is a very cocky , overconfident xxmaj ashton xxmaj kutcher . xxmaj the problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . xxmaj his only obstacle appears to be winning over xxmaj costner . xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>happening up , close &amp; personal . xxmaj what appears on screen is mostly the aftermath of the killer 's vengeance : one fellow holding his guts , another with a xxunk up the group 's volleyball net ) plunged through his chest , blood spatter after a woman gets hit over the head presumably with a large rock , one chick laying dead after the scarecrow hit her with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>xxmaj johnny xxmaj sokko ( ? ) , a young boy who controls a xxmaj giant xxmaj robot , and his fight against the evil xxmaj gargoyle xxmaj gang , who seem to have an endless supply of horrid giant monsters at their disposal . xxbos xxmaj watching this movie brings several words to mind : \" sophomoric \" , \" ridiculous \" , \" improbable \" , \" self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>america . xxmaj no mention that a lot of people have died . \\n \\n  xxmaj then there 's xxmaj michael xxmaj clarke xxmaj duncan . a wonderful actor , wasted . xxmaj never has a black man been so token . xxmaj among a team of hardcore drillers , his job seems to consist of standing in the back , occasionally saying \" xxmaj hey , you da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>still not sure it was worth it ... xxbos xxmaj let me say at the outset that i 'm not a very artistic person and that i do n't \" get \" new art . xxmaj that being said , this film is absolutely crazy , and in my opinion not crazy in a good way . xxmaj filmed entirely in black and white with a series of very loosely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.137822</td>\n",
       "      <td>4.020172</td>\n",
       "      <td>0.295707</td>\n",
       "      <td>21:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfeeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.844263</td>\n",
       "      <td>3.813834</td>\n",
       "      <td>0.317698</td>\n",
       "      <td>24:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.802978</td>\n",
       "      <td>3.772527</td>\n",
       "      <td>0.324902</td>\n",
       "      <td>25:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.793264</td>\n",
       "      <td>3.741329</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>24:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.719896</td>\n",
       "      <td>3.705808</td>\n",
       "      <td>0.333661</td>\n",
       "      <td>25:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.671008</td>\n",
       "      <td>3.675662</td>\n",
       "      <td>0.336757</td>\n",
       "      <td>24:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.609677</td>\n",
       "      <td>3.649988</td>\n",
       "      <td>0.339925</td>\n",
       "      <td>24:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.494647</td>\n",
       "      <td>3.631659</td>\n",
       "      <td>0.342422</td>\n",
       "      <td>25:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.481280</td>\n",
       "      <td>3.619783</td>\n",
       "      <td>0.344014</td>\n",
       "      <td>25:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.409071</td>\n",
       "      <td>3.617496</td>\n",
       "      <td>0.344400</td>\n",
       "      <td>24:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.381227</td>\n",
       "      <td>3.619449</td>\n",
       "      <td>0.344422</td>\n",
       "      <td>1:21:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('fine_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model? Well let's try to see what it predicts after a few given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I liked this movie because i really liked the first part of the film . It was very entertaining . It was not put in on the same earth as the first movie . The acting was great . The movie\n",
      "I liked this movie because of the other actors . i love Ben Stiller and Jack Black . They were just great . They both add a lot of class to this movie . And , of course\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to save not only the model, but also its encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj the vigilante has long held a fascination for audiences , inasmuch as it evokes a sense of swift , sure justice ; good triumphs over evil and the bad guy gets his deserts . xxmaj it is , in fact , one of the things that has made the character of xxmaj dirty xxmaj harry xxmaj callahan ( as played by xxmaj clint xxmaj eastwood ) so popular</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxup spoilers xxup herein \\n \\n  xxmaj my xxmaj high xxmaj school did all they could to try and motivate us for exams . xxmaj but the most memorable method they used to get us into the right state of mind was a guest speaker , who was none other than xxmaj australian xxmaj kickboxing 's favorite son , xxmaj stan \" xxmaj the xxmaj man \" xxmaj</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj anyone who visited drive - ins in the 1950s , 60s , and 70s , must have seen a film or two by xxmaj american xxmaj international xxmaj pictures , a distributor that resembled 1980s giant xxmaj cannon xxmaj films . xxmaj wherever movie - goers ventured , xxup aip would be right there to supply the latest en vogue titles - in the 50s came horror movies</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxup oliver xxup twist was to have controversy as well as success following it after xxmaj dickens published it in 1837 . xxmaj his picture of life in the urban ghettos was something shocking and new , and his making the central figures of the novel include criminals was another innovation . \\n \\n  xxmaj one day he was walking in xxmaj london and passed a young woman</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj story of a man who has unnatural feelings for a pig . xxmaj starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane , violent mob by the crazy xxunk of it 's singers . xxmaj unfortunately it stays absurd the xxup whole time with no general narrative eventually making it just too off putting . xxmaj even those from the era should be turned off . xxmaj the cryptic dialogue would make xxmaj shakespeare seem easy to a third grader . xxmaj on a technical level it 's better than you might think with some good cinematography by future great xxmaj vilmos xxmaj zsigmond . xxmaj future stars xxmaj sally xxmaj kirkland and xxmaj frederic xxmaj forrest can be seen briefly .,xxbos xxmaj airport ' 77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman xxmaj philip xxmaj stevens ( xxmaj james xxmaj stewart ) who is flying them & a bunch of xxup vip 's to his estate in preparation of it being opened to the public as a museum , also on board is xxmaj stevens daughter xxmaj julie ( xxmaj kathleen xxmaj quinlan ) & her son . xxmaj the luxury jetliner takes off as planned but mid - air the plane is hi - jacked by the co - pilot xxmaj chambers ( xxmaj robert xxmaj foxworth ) & his two accomplice 's xxmaj banker ( xxmaj monte xxmaj markham ) & xxmaj wilson ( xxmaj michael xxmaj pataki ) who knock the passengers & crew out with sleeping gas , they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent xxmaj chambers almost hits an oil rig in the xxmaj ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the xxmaj bermuda xxmaj triangle . xxmaj with air in short supply , water leaking in & having flown over 200 miles off course the problems mount for the survivor 's as they await help with time fast running out ... \n",
       " \n",
       "  xxmaj also known under the slightly different tile xxmaj airport 1977 this second sequel to the smash - hit disaster thriller xxmaj airport ( 1970 ) was directed by xxmaj jerry xxmaj jameson & while once again like it 's predecessors i ca n't say xxmaj airport ' 77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons . xxmaj out of the three xxmaj airport films i have seen so far i actually liked this one the best , just . xxmaj it has my favourite plot of the three with a nice mid - air hi - jacking & then the crashing ( did n't he see the oil rig ? ) & sinking of the 747 ( maybe the makers were trying to cross the original xxmaj airport with another popular disaster flick of the period xxmaj the xxmaj poseidon xxmaj adventure ( 1972 ) ) & submerged is where it stays until the end with a stark dilemma facing those trapped inside , either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it 's a decent idea that could have made for a great little disaster flick but bad unsympathetic character 's , dull dialogue , lethargic set - pieces & a real lack of danger or suspense or tension means this is a missed opportunity . xxmaj while the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there 's not as much urgency as i thought there should have been . xxmaj even when the xxmaj navy become involved things do n't pick up that much with a few shots of huge ships & helicopters flying about but there 's just something lacking here . xxmaj george xxmaj kennedy as the xxunk airline worker xxmaj joe xxmaj patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background . \n",
       " \n",
       "  xxmaj the home video & theatrical version of xxmaj airport ' 77 run 108 minutes while the xxup us xxup tv versions add an extra hour of footage including a new opening credits sequence , many more scenes with xxmaj george xxmaj kennedy as xxmaj patroni , flashbacks to flesh out character 's , longer rescue scenes & the discovery or another couple of dead bodies including the navigator . xxmaj while i would like to see this extra footage i am not sure i could sit through a near three hour cut of xxmaj airport ' 77 . xxmaj as expected the film has dated badly with horrible fashions & interior design choices , i will say no more other than the toy plane model effects are n't great either . xxmaj along with the other two xxmaj airport sequels this takes pride of place in the xxmaj razzie xxmaj award 's xxmaj hall of xxmaj shame although i can think of lots of worse films than this so i reckon that 's a little harsh . xxmaj the action scenes are a little dull unfortunately , the pace is slow & not much excitement or tension is generated which is a shame as i reckon this could have been a pretty good film if made properly . \n",
       " \n",
       "  xxmaj the production values are alright if nothing spectacular . xxmaj the acting is n't great , two time xxmaj oscar winner xxmaj jack xxmaj lemmon has said since it was a mistake to star in this , one time xxmaj oscar winner xxmaj james xxmaj stewart looks old & frail , also one time xxmaj oscar winner xxmaj lee xxmaj grant looks drunk while xxmaj sir xxmaj christopher xxmaj lee is given little to do & there are plenty of other familiar faces to look out for too . \n",
       " \n",
       "  xxmaj airport ' 77 is the most disaster orientated of the three xxmaj airport films so far & i liked the ideas behind it even if they were a bit silly , the production & bland direction does n't help though & a film about a sunken plane just should n't be this boring or lethargic . xxmaj followed by xxmaj the xxmaj concorde ... xxmaj airport ' 79 ( 1979 ) .,xxbos xxmaj this film lacked something i could n't put my finger on at first : charisma on the part of the leading actress . xxmaj this inevitably translated to lack of chemistry when she shared the screen with her leading man . xxmaj even the romantic scenes came across as being merely the actors at play . xxmaj it could very well have been the director who miscalculated what he needed from the actors . i just do n't know . \n",
       " \n",
       "  xxmaj but could it have been the screenplay ? xxmaj just exactly who was the chef in love with ? xxmaj he seemed more enamored of his culinary skills and restaurant , and ultimately of himself and his youthful exploits , than of anybody or anything else . xxmaj he never convinced me he was in love with the princess . \n",
       " \n",
       "  i was disappointed in this movie . xxmaj but , do n't forget it was nominated for an xxmaj oscar , so judge for yourself .,xxbos xxmaj sorry everyone , , , i know this is supposed to be an \" art \" film , , but wow , they should have handed out guns at the screening so people could blow their brains out and not watch . xxmaj although the scene design and photographic direction was excellent , this story is too painful to watch . xxmaj the absence of a sound track was brutal . xxmaj the l xxrep 4 o xxrep 5 n g shots were too long . xxmaj how long can you watch two people just sitting there and talking ? xxmaj especially when the dialogue is two people complaining . i really had a hard time just getting through this film . xxmaj the performances were excellent , but how much of that dark , sombre , uninspired , stuff can you take ? xxmaj the only thing i liked was xxmaj maureen xxmaj stapleton and her red dress and dancing scene . xxmaj otherwise this was a ripoff of xxmaj bergman . xxmaj and i 'm no fan f his either . i think anyone who says they enjoyed 1 1 / 2 hours of this is , , well , lying .,xxbos xxmaj when i was little my parents took me along to the theater to see xxmaj interiors . xxmaj it was one of many movies i watched with my parents , but this was the only one we walked out of . xxmaj since then i had never seen xxmaj interiors until just recently , and i could have lived out the rest of my life without it . xxmaj what a pretentious , ponderous , and painfully boring piece of 70 's wine and cheese tripe . xxmaj woody xxmaj allen is one of my favorite directors but xxmaj interiors is by far the worst piece of crap of his career . xxmaj in the unmistakable style of xxmaj ingmar xxmaj berman , xxmaj allen gives us a dark , angular , muted , insight in to the lives of a family wrought by the psychological damage caused by divorce , estrangement , career , love , non - love , xxunk , whatever . xxmaj the film , intentionally , has no comic relief , no music , and is drenched in shadowy pathos . xxmaj this film style can be best defined as expressionist in nature , using an improvisational method of dialogue to illicit a \" more pronounced depth of meaning and truth \" . xxmaj but xxmaj woody xxmaj allen is no xxmaj ingmar xxmaj bergman . xxmaj the film is painfully slow and dull . xxmaj but beyond that , i simply had no connection with or sympathy for any of the characters . xxmaj instead i felt only contempt for this parade of shuffling , whining , nicotine stained , martyrs in a perpetual quest for identity . xxmaj amid a backdrop of cosmopolitan affluence and baked xxmaj brie intelligentsia the story looms like a fart in the room . xxmaj everyone speaks in affected platitudes and elevated language between cigarettes . xxmaj everyone is \" lost \" and \" struggling \" , desperate to find direction or understanding or whatever and it just goes on and on to the point where you just want to slap all of them . xxmaj it 's never about resolution , it 's only about interminable introspective babble . xxmaj it is nothing more than a psychological drama taken to an extreme beyond the audience 's ability to connect . xxmaj woody xxmaj allen chose to make characters so immersed in themselves we feel left out . xxmaj and for that reason i found this movie painfully self indulgent and spiritually draining . i see what he was going for but his insistence on promoting his message through xxmaj prozac prose and distorted film techniques jettisons it past the point of relevance . i highly recommend this one if you 're feeling a little too happy and need something to remind you of death . xxmaj otherwise , let 's just pretend this film never happened .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: C:\\Users\\User\\.fastai\\data\\imdb;\n",
       "\n",
       "Valid: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj once again xxmaj mr. xxmaj costner has dragged out a movie for far longer than necessary . xxmaj aside from the terrific sea rescue sequences , of which there are very few i just did not care about any of the characters . xxmaj most of us have ghosts in the closet , and xxmaj costner 's character are realized early on , and then forgotten until much later , by which time i did not care . xxmaj the character we should really care about is a very cocky , overconfident xxmaj ashton xxmaj kutcher . xxmaj the problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . xxmaj his only obstacle appears to be winning over xxmaj costner . xxmaj finally when we are well past the half way point of this stinker , xxmaj costner tells us all about xxmaj kutcher 's ghosts . xxmaj we are told why xxmaj kutcher is driven to be the best with no prior inkling or foreshadowing . xxmaj no magic here , it was all i could do to keep from turning it off an hour in .,xxbos xxmaj this is an example of why the majority of action films are the same . xxmaj generic and boring , there 's really nothing worth watching here . a complete waste of the then barely - tapped talents of xxmaj ice - t and xxmaj ice xxmaj cube , who 've each proven many times over that they are capable of acting , and acting well . xxmaj do n't bother with this one , go see xxmaj new xxmaj jack xxmaj city , xxmaj ricochet or watch xxmaj new xxmaj york xxmaj undercover for xxmaj ice - t , or xxmaj boyz n the xxmaj hood , xxmaj higher xxmaj learning or xxmaj friday for xxmaj ice xxmaj cube and see the real deal . xxmaj ice - t 's horribly cliched dialogue alone makes this film grate at the teeth , and i 'm still wondering what the heck xxmaj bill xxmaj paxton was doing in this film ? xxmaj and why the heck does he always play the exact same character ? xxmaj from xxmaj aliens onward , every film i 've seen with xxmaj bill xxmaj paxton has him playing the exact same irritating character , and at least in xxmaj aliens his character died , which made it somewhat gratifying ... \n",
       " \n",
       "  xxmaj overall , this is second - rate action trash . xxmaj there are countless better films to see , and if you really want to see this one , watch xxmaj judgement xxmaj night , which is practically a carbon copy but has better acting and a better script . xxmaj the only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing , which comes close to making up for the horrible film itself - but not quite . 4 / 10 .,xxbos xxmaj first of all i hate those moronic rappers , who could'nt act if they had a gun pressed against their foreheads . xxmaj all they do is curse and shoot each other and acting like xxunk version of gangsters . \n",
       " \n",
       "  xxmaj the movie does n't take more than five minutes to explain what is going on before we 're already at the warehouse xxmaj there is not a single sympathetic character in this movie , except for the homeless guy , who is also the only one with half a brain . \n",
       " \n",
       "  xxmaj bill xxmaj paxton and xxmaj william xxmaj sadler are both hill billies and xxmaj xxunk character is just as much a villain as the gangsters . i did'nt like him right from the start . \n",
       " \n",
       "  xxmaj the movie is filled with pointless violence and xxmaj walter xxmaj hills specialty : people falling through windows with glass flying everywhere . xxmaj there is pretty much no plot and it is a big problem when you root for no - one . xxmaj everybody dies , except from xxmaj paxton and the homeless guy and everybody get what they deserve . \n",
       " \n",
       "  xxmaj the only two black people that can act is the homeless guy and the junkie but they 're actors by profession , not annoying ugly brain dead rappers . \n",
       " \n",
       "  xxmaj stay away from this crap and watch 48 hours 1 and 2 instead . xxmaj at lest they have characters you care about , a sense of humor and nothing but real actors in the cast .,xxbos xxmaj not even the xxmaj beatles could write songs everyone liked , and although xxmaj walter xxmaj hill is no mop - top he 's second to none when it comes to thought provoking action movies . xxmaj the nineties came and social platforms were changing in music and film , the emergence of the xxmaj rapper turned movie star was in full swing , the acting took a back seat to each man 's overpowering regional accent and transparent acting . xxmaj this was one of the many ice - t movies i saw as a kid and loved , only to watch them later and cringe . xxmaj bill xxmaj paxton and xxmaj william xxmaj sadler are firemen with basic lives until a burning building tenant about to go up in flames hands over a map with gold implications . i hand it to xxmaj walter for quickly and neatly setting up the main characters and location . xxmaj but i fault everyone involved for turning out xxmaj lame - o performances . xxmaj ice - t and cube must have been red hot at this time , and while i 've enjoyed both their careers as rappers , in my opinion they fell flat in this movie . xxmaj it 's about ninety minutes of one guy ridiculously turning his back on the other guy to the point you find yourself locked in multiple states of disbelief . xxmaj now this is a movie , its not a documentary so i wo nt waste my time recounting all the stupid plot twists in this movie , but there were many , and they led nowhere . i got the feeling watching this that everyone on set was xxunk of confused and just playing things off the cuff . xxmaj there are two things i still enjoy about it , one involves a scene with a needle and the other is xxmaj sadler 's huge 45 pistol . xxmaj bottom line this movie is like domino 's pizza . xxmaj yeah ill eat it if i 'm hungry and i do n't feel like cooking , xxmaj but i 'm well aware it tastes like crap . 3 stars , meh .,xxbos xxmaj brass pictures ( movies is not a fitting word for them ) really are somewhat brassy . xxmaj their alluring visual qualities are reminiscent of expensive high class xxup tv commercials . xxmaj but unfortunately xxmaj brass pictures are feature films with the pretense of wanting to entertain viewers for over two hours ! xxmaj in this they fail miserably , their undeniable , but rather soft and flabby than steamy , erotic qualities non withstanding . \n",
       " \n",
       "  xxmaj senso ' 45 is a remake of a film by xxmaj luchino xxmaj visconti with the same title and xxmaj alida xxmaj valli and xxmaj farley xxmaj granger in the lead . xxmaj the original tells a story of senseless love and lust in and around xxmaj venice during the xxmaj italian wars of independence . xxmaj brass moved the action from the 19th into the 20th century , 1945 to be exact , so there are xxmaj mussolini murals , men in black shirts , xxmaj german uniforms or the tattered garb of the partisans . xxmaj but it is just window dressing , the historic context is completely negligible . \n",
       " \n",
       "  xxmaj anna xxmaj xxunk plays the attractive aristocratic woman who falls for the amoral xxup ss guy who always puts on too much lipstick . xxmaj she is an attractive , versatile , well trained xxmaj italian actress and clearly above the material . xxmaj her wide range of facial expressions ( signalling boredom , loathing , delight , fear , hate ... and ecstasy ) are the best reason to watch this picture and worth two stars . xxmaj she endures this basically trashy stuff with an astonishing amount of dignity . i wish some really good parts come along for her . xxmaj she really deserves it .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: C:\\Users\\User\\.fastai\\data\\imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x0000016F67210A60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('C:/Users/User/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj story of a man who has unnatural feelings for a pig . xxmaj starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane , violent mob by the crazy xxunk of it 's singers . xxmaj unfortunately it stays absurd the xxup whole time with no general narrative eventually making it just too off putting . xxmaj even those from the era should be turned off . xxmaj the cryptic dialogue would make xxmaj shakespeare seem easy to a third grader . xxmaj on a technical level it 's better than you might think with some good cinematography by future great xxmaj vilmos xxmaj zsigmond . xxmaj future stars xxmaj sally xxmaj kirkland and xxmaj frederic xxmaj forrest can be seen briefly .,xxbos xxmaj airport ' 77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman xxmaj philip xxmaj stevens ( xxmaj james xxmaj stewart ) who is flying them & a bunch of xxup vip 's to his estate in preparation of it being opened to the public as a museum , also on board is xxmaj stevens daughter xxmaj julie ( xxmaj kathleen xxmaj quinlan ) & her son . xxmaj the luxury jetliner takes off as planned but mid - air the plane is hi - jacked by the co - pilot xxmaj chambers ( xxmaj robert xxmaj foxworth ) & his two accomplice 's xxmaj banker ( xxmaj monte xxmaj markham ) & xxmaj wilson ( xxmaj michael xxmaj pataki ) who knock the passengers & crew out with sleeping gas , they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent xxmaj chambers almost hits an oil rig in the xxmaj ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the xxmaj bermuda xxmaj triangle . xxmaj with air in short supply , water leaking in & having flown over 200 miles off course the problems mount for the survivor 's as they await help with time fast running out ... \n",
       " \n",
       "  xxmaj also known under the slightly different tile xxmaj airport 1977 this second sequel to the smash - hit disaster thriller xxmaj airport ( 1970 ) was directed by xxmaj jerry xxmaj jameson & while once again like it 's predecessors i ca n't say xxmaj airport ' 77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons . xxmaj out of the three xxmaj airport films i have seen so far i actually liked this one the best , just . xxmaj it has my favourite plot of the three with a nice mid - air hi - jacking & then the crashing ( did n't he see the oil rig ? ) & sinking of the 747 ( maybe the makers were trying to cross the original xxmaj airport with another popular disaster flick of the period xxmaj the xxmaj poseidon xxmaj adventure ( 1972 ) ) & submerged is where it stays until the end with a stark dilemma facing those trapped inside , either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it 's a decent idea that could have made for a great little disaster flick but bad unsympathetic character 's , dull dialogue , lethargic set - pieces & a real lack of danger or suspense or tension means this is a missed opportunity . xxmaj while the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there 's not as much urgency as i thought there should have been . xxmaj even when the xxmaj navy become involved things do n't pick up that much with a few shots of huge ships & helicopters flying about but there 's just something lacking here . xxmaj george xxmaj kennedy as the xxunk airline worker xxmaj joe xxmaj patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background . \n",
       " \n",
       "  xxmaj the home video & theatrical version of xxmaj airport ' 77 run 108 minutes while the xxup us xxup tv versions add an extra hour of footage including a new opening credits sequence , many more scenes with xxmaj george xxmaj kennedy as xxmaj patroni , flashbacks to flesh out character 's , longer rescue scenes & the discovery or another couple of dead bodies including the navigator . xxmaj while i would like to see this extra footage i am not sure i could sit through a near three hour cut of xxmaj airport ' 77 . xxmaj as expected the film has dated badly with horrible fashions & interior design choices , i will say no more other than the toy plane model effects are n't great either . xxmaj along with the other two xxmaj airport sequels this takes pride of place in the xxmaj razzie xxmaj award 's xxmaj hall of xxmaj shame although i can think of lots of worse films than this so i reckon that 's a little harsh . xxmaj the action scenes are a little dull unfortunately , the pace is slow & not much excitement or tension is generated which is a shame as i reckon this could have been a pretty good film if made properly . \n",
       " \n",
       "  xxmaj the production values are alright if nothing spectacular . xxmaj the acting is n't great , two time xxmaj oscar winner xxmaj jack xxmaj lemmon has said since it was a mistake to star in this , one time xxmaj oscar winner xxmaj james xxmaj stewart looks old & frail , also one time xxmaj oscar winner xxmaj lee xxmaj grant looks drunk while xxmaj sir xxmaj christopher xxmaj lee is given little to do & there are plenty of other familiar faces to look out for too . \n",
       " \n",
       "  xxmaj airport ' 77 is the most disaster orientated of the three xxmaj airport films so far & i liked the ideas behind it even if they were a bit silly , the production & bland direction does n't help though & a film about a sunken plane just should n't be this boring or lethargic . xxmaj followed by xxmaj the xxmaj concorde ... xxmaj airport ' 79 ( 1979 ) .,xxbos xxmaj this film lacked something i could n't put my finger on at first : charisma on the part of the leading actress . xxmaj this inevitably translated to lack of chemistry when she shared the screen with her leading man . xxmaj even the romantic scenes came across as being merely the actors at play . xxmaj it could very well have been the director who miscalculated what he needed from the actors . i just do n't know . \n",
       " \n",
       "  xxmaj but could it have been the screenplay ? xxmaj just exactly who was the chef in love with ? xxmaj he seemed more enamored of his culinary skills and restaurant , and ultimately of himself and his youthful exploits , than of anybody or anything else . xxmaj he never convinced me he was in love with the princess . \n",
       " \n",
       "  i was disappointed in this movie . xxmaj but , do n't forget it was nominated for an xxmaj oscar , so judge for yourself .,xxbos xxmaj sorry everyone , , , i know this is supposed to be an \" art \" film , , but wow , they should have handed out guns at the screening so people could blow their brains out and not watch . xxmaj although the scene design and photographic direction was excellent , this story is too painful to watch . xxmaj the absence of a sound track was brutal . xxmaj the l xxrep 4 o xxrep 5 n g shots were too long . xxmaj how long can you watch two people just sitting there and talking ? xxmaj especially when the dialogue is two people complaining . i really had a hard time just getting through this film . xxmaj the performances were excellent , but how much of that dark , sombre , uninspired , stuff can you take ? xxmaj the only thing i liked was xxmaj maureen xxmaj stapleton and her red dress and dancing scene . xxmaj otherwise this was a ripoff of xxmaj bergman . xxmaj and i 'm no fan f his either . i think anyone who says they enjoyed 1 1 / 2 hours of this is , , well , lying .,xxbos xxmaj when i was little my parents took me along to the theater to see xxmaj interiors . xxmaj it was one of many movies i watched with my parents , but this was the only one we walked out of . xxmaj since then i had never seen xxmaj interiors until just recently , and i could have lived out the rest of my life without it . xxmaj what a pretentious , ponderous , and painfully boring piece of 70 's wine and cheese tripe . xxmaj woody xxmaj allen is one of my favorite directors but xxmaj interiors is by far the worst piece of crap of his career . xxmaj in the unmistakable style of xxmaj ingmar xxmaj berman , xxmaj allen gives us a dark , angular , muted , insight in to the lives of a family wrought by the psychological damage caused by divorce , estrangement , career , love , non - love , xxunk , whatever . xxmaj the film , intentionally , has no comic relief , no music , and is drenched in shadowy pathos . xxmaj this film style can be best defined as expressionist in nature , using an improvisational method of dialogue to illicit a \" more pronounced depth of meaning and truth \" . xxmaj but xxmaj woody xxmaj allen is no xxmaj ingmar xxmaj bergman . xxmaj the film is painfully slow and dull . xxmaj but beyond that , i simply had no connection with or sympathy for any of the characters . xxmaj instead i felt only contempt for this parade of shuffling , whining , nicotine stained , martyrs in a perpetual quest for identity . xxmaj amid a backdrop of cosmopolitan affluence and baked xxmaj brie intelligentsia the story looms like a fart in the room . xxmaj everyone speaks in affected platitudes and elevated language between cigarettes . xxmaj everyone is \" lost \" and \" struggling \" , desperate to find direction or understanding or whatever and it just goes on and on to the point where you just want to slap all of them . xxmaj it 's never about resolution , it 's only about interminable introspective babble . xxmaj it is nothing more than a psychological drama taken to an extreme beyond the audience 's ability to connect . xxmaj woody xxmaj allen chose to make characters so immersed in themselves we feel left out . xxmaj and for that reason i found this movie painfully self indulgent and spiritually draining . i see what he was going for but his insistence on promoting his message through xxmaj prozac prose and distorted film techniques jettisons it past the point of relevance . i highly recommend this one if you 're feeling a little too happy and need something to remind you of death . xxmaj otherwise , let 's just pretend this film never happened .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: C:\\Users\\User\\.fastai\\data\\imdb;\n",
       "\n",
       "Valid: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj once again xxmaj mr. xxmaj costner has dragged out a movie for far longer than necessary . xxmaj aside from the terrific sea rescue sequences , of which there are very few i just did not care about any of the characters . xxmaj most of us have ghosts in the closet , and xxmaj costner 's character are realized early on , and then forgotten until much later , by which time i did not care . xxmaj the character we should really care about is a very cocky , overconfident xxmaj ashton xxmaj kutcher . xxmaj the problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . xxmaj his only obstacle appears to be winning over xxmaj costner . xxmaj finally when we are well past the half way point of this stinker , xxmaj costner tells us all about xxmaj kutcher 's ghosts . xxmaj we are told why xxmaj kutcher is driven to be the best with no prior inkling or foreshadowing . xxmaj no magic here , it was all i could do to keep from turning it off an hour in .,xxbos xxmaj this is an example of why the majority of action films are the same . xxmaj generic and boring , there 's really nothing worth watching here . a complete waste of the then barely - tapped talents of xxmaj ice - t and xxmaj ice xxmaj cube , who 've each proven many times over that they are capable of acting , and acting well . xxmaj do n't bother with this one , go see xxmaj new xxmaj jack xxmaj city , xxmaj ricochet or watch xxmaj new xxmaj york xxmaj undercover for xxmaj ice - t , or xxmaj boyz n the xxmaj hood , xxmaj higher xxmaj learning or xxmaj friday for xxmaj ice xxmaj cube and see the real deal . xxmaj ice - t 's horribly cliched dialogue alone makes this film grate at the teeth , and i 'm still wondering what the heck xxmaj bill xxmaj paxton was doing in this film ? xxmaj and why the heck does he always play the exact same character ? xxmaj from xxmaj aliens onward , every film i 've seen with xxmaj bill xxmaj paxton has him playing the exact same irritating character , and at least in xxmaj aliens his character died , which made it somewhat gratifying ... \n",
       " \n",
       "  xxmaj overall , this is second - rate action trash . xxmaj there are countless better films to see , and if you really want to see this one , watch xxmaj judgement xxmaj night , which is practically a carbon copy but has better acting and a better script . xxmaj the only thing that made this at all worth watching was a decent hand on the camera - the cinematography was almost refreshing , which comes close to making up for the horrible film itself - but not quite . 4 / 10 .,xxbos xxmaj first of all i hate those moronic rappers , who could'nt act if they had a gun pressed against their foreheads . xxmaj all they do is curse and shoot each other and acting like xxunk version of gangsters . \n",
       " \n",
       "  xxmaj the movie does n't take more than five minutes to explain what is going on before we 're already at the warehouse xxmaj there is not a single sympathetic character in this movie , except for the homeless guy , who is also the only one with half a brain . \n",
       " \n",
       "  xxmaj bill xxmaj paxton and xxmaj william xxmaj sadler are both hill billies and xxmaj xxunk character is just as much a villain as the gangsters . i did'nt like him right from the start . \n",
       " \n",
       "  xxmaj the movie is filled with pointless violence and xxmaj walter xxmaj hills specialty : people falling through windows with glass flying everywhere . xxmaj there is pretty much no plot and it is a big problem when you root for no - one . xxmaj everybody dies , except from xxmaj paxton and the homeless guy and everybody get what they deserve . \n",
       " \n",
       "  xxmaj the only two black people that can act is the homeless guy and the junkie but they 're actors by profession , not annoying ugly brain dead rappers . \n",
       " \n",
       "  xxmaj stay away from this crap and watch 48 hours 1 and 2 instead . xxmaj at lest they have characters you care about , a sense of humor and nothing but real actors in the cast .,xxbos xxmaj not even the xxmaj beatles could write songs everyone liked , and although xxmaj walter xxmaj hill is no mop - top he 's second to none when it comes to thought provoking action movies . xxmaj the nineties came and social platforms were changing in music and film , the emergence of the xxmaj rapper turned movie star was in full swing , the acting took a back seat to each man 's overpowering regional accent and transparent acting . xxmaj this was one of the many ice - t movies i saw as a kid and loved , only to watch them later and cringe . xxmaj bill xxmaj paxton and xxmaj william xxmaj sadler are firemen with basic lives until a burning building tenant about to go up in flames hands over a map with gold implications . i hand it to xxmaj walter for quickly and neatly setting up the main characters and location . xxmaj but i fault everyone involved for turning out xxmaj lame - o performances . xxmaj ice - t and cube must have been red hot at this time , and while i 've enjoyed both their careers as rappers , in my opinion they fell flat in this movie . xxmaj it 's about ninety minutes of one guy ridiculously turning his back on the other guy to the point you find yourself locked in multiple states of disbelief . xxmaj now this is a movie , its not a documentary so i wo nt waste my time recounting all the stupid plot twists in this movie , but there were many , and they led nowhere . i got the feeling watching this that everyone on set was xxunk of confused and just playing things off the cuff . xxmaj there are two things i still enjoy about it , one involves a scene with a needle and the other is xxmaj sadler 's huge 45 pistol . xxmaj bottom line this movie is like domino 's pizza . xxmaj yeah ill eat it if i 'm hungry and i do n't feel like cooking , xxmaj but i 'm well aware it tastes like crap . 3 stars , meh .,xxbos xxmaj brass pictures ( movies is not a fitting word for them ) really are somewhat brassy . xxmaj their alluring visual qualities are reminiscent of expensive high class xxup tv commercials . xxmaj but unfortunately xxmaj brass pictures are feature films with the pretense of wanting to entertain viewers for over two hours ! xxmaj in this they fail miserably , their undeniable , but rather soft and flabby than steamy , erotic qualities non withstanding . \n",
       " \n",
       "  xxmaj senso ' 45 is a remake of a film by xxmaj luchino xxmaj visconti with the same title and xxmaj alida xxmaj valli and xxmaj farley xxmaj granger in the lead . xxmaj the original tells a story of senseless love and lust in and around xxmaj venice during the xxmaj italian wars of independence . xxmaj brass moved the action from the 19th into the 20th century , 1945 to be exact , so there are xxmaj mussolini murals , men in black shirts , xxmaj german uniforms or the tattered garb of the partisans . xxmaj but it is just window dressing , the historic context is completely negligible . \n",
       " \n",
       "  xxmaj anna xxmaj xxunk plays the attractive aristocratic woman who falls for the amoral xxup ss guy who always puts on too much lipstick . xxmaj she is an attractive , versatile , well trained xxmaj italian actress and clearly above the material . xxmaj her wide range of facial expressions ( signalling boredom , loathing , delight , fear , hate ... and ecstasy ) are the best reason to watch this picture and worth two stars . xxmaj she endures this basically trashy stuff with an astonishing amount of dignity . i wish some really good parts come along for her . xxmaj she really deserves it .\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: C:\\Users\\User\\.fastai\\data\\imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x0000016F67210A60>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=WindowsPath('C:/Users/User/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(60000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.279292</td>\n",
       "      <td>0.178286</td>\n",
       "      <td>0.932880</td>\n",
       "      <td>05:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.230728</td>\n",
       "      <td>0.164024</td>\n",
       "      <td>0.938800</td>\n",
       "      <td>05:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('second');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.195398</td>\n",
       "      <td>0.143161</td>\n",
       "      <td>0.948720</td>\n",
       "      <td>06:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 91.63 MiB (GPU 0; 11.00 GiB total capacity; 8.44 GiB already allocated; 29.22 MiB free; 201.86 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-8c22c7d70798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.6\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[0;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[0;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[1;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0myb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\text\\learner.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mraw_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m             \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\text\\models\\awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, from_embeddings)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mraw_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfrom_embeddings\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_dp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mnew_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\text\\models\\awd_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, words, scale)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mmasked_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmasked_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmasked_embed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 91.63 MiB (GPU 0; 11.00 GiB total capacity; 8.44 GiB already allocated; 29.22 MiB free; 201.86 MiB cached)"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\fastai_v1\\lib\\site-packages\\fastai\\torch_core.py:83: UserWarning: Tensor is int32: upgrading to int64; for better performance use int64 input\n",
      "  warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([7.2650e-05, 9.9993e-01]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"提問: 對於不同於ImageNet的數據集，比如說衛星圖或者生物圖，我們應該使用我們自己的統計分佈（stats）。\n",
    "Jeremy 說過：\n",
    "如果你使用預訓練的模型，你需要使用和預訓練相同的stats。\n",
    "這是為什麼？是不是使用自己的stats標準化的模型有和ImageNet基本一樣的分佈？唯一我能想到的不同的地方是偏度（skewness）。\n",
    "你這麼說是因為偏度還是其他的東西？這是否代表對於差別比較大的數據集你不推薦使用預訓練模型？ \n",
    "\n",
    "\n",
    "不是。你可以看到，我在所有的地方都用了預訓練模型。每次我用ImageNet預訓練模型時，我都使用ImageNet stats。為什麼呢？因為模型是用這些stats訓練的。\n",
    "比如說，假如你在分類不同品種的綠青蛙。\n",
    "如果你使用自己數據集每個channel（紅藍綠）均值，你最終會把它們轉換成在每個channel上服從均值為0標準差為1的分佈。\n",
    "這意味者它們不再像綠青蛙了。而是像灰青蛙。但是ImageNet希望青蛙是綠的。所以你需要用ImageNet訓練者使用的stats做標準化。\n",
    "否則你的數據集的唯一特徵會不見，你在做標準化時把它們丟失了。所以你需要使用和訓練時相同的stats。\n",
    "每個例子裡我們都是用mini batch做梯度下降（隨機梯度下降）來擬合模型參數。這些參數是用來做矩陣乘法的。\n",
    "這個課程的後半部分裡，我們會學習卷積，這也是一種矩陣乘法。\n",
    "儘管沒有矩陣乘法運算可以創建出這樣的東西：可以識別電影評論是正面還是負面、看出衛星圖識別出上面有沒有道路。\n",
    "這遠遠不是線性分類器可以做到的。現在我們知道這是深度神經網絡。深度神經網絡包含很多這樣的矩陣乘法，每個矩陣乘法運算都是一個線性分類器。\n",
    "一個線性函數在另一個的上層。如果你回憶高中數學，你可能會記得如果你有一個y=ax+b，然後在它上面做cy+d ，\n",
    "它還是一個有不同斜率和截距的線性函數。所以矩陣乘法運算不會有任何幫助。\n",
    "\n",
    "這些模型實質上是什麼呢？我們實質上在做什麼？這是個有意思的事情：\n",
    "我們確實做了矩陣乘法運算（或者像卷積這樣的變種），但每做一次矩陣乘法後，我們會做一次非線性計算或者叫激活函數。\n",
    "激活函數把矩陣乘法的結果作為輸入，在上面做些處理。這是一些我們用到的激活函數 (by Sagar Sharma):\n",
    "以前，最常用的函數是sigmoid。它們有特定的數學定義。現在我們幾乎不用這個了。\n",
    "我們現在是用rectified linear unit (ReLU)。當你做深度學習時，用很大很長的、引人注意的詞很重要。\n",
    "否則普通人會覺得他也可以做。但是，只告訴你們，rectified linear unit是用這樣的函數定義的:\n",
    "max(x, 0)\n",
    "就是這樣。如果你想高大上些，你可以用縮寫ReLU，來顯示你在一個高大上的團隊裡。這就是ReLU激活函數。\n",
    "這是神奇的事情。如果你把紅綠藍像素值輸入，做矩陣乘法運算，把負值用0替代，做另外一個矩陣運算，把負值用0替代，你不停地這樣做，就能得到一個神經網絡。就是這樣而已\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://neuralnetworksanddeeplearning.com\n",
    "http://neuralnetworksanddeeplearning.com/chap4.html\n",
    "\"\"\"通用逼近定理Universal approximation theorem \n",
    "\n",
    "這是怎樣做到的呢？一個特別酷的叫Michael Nielsen的傢伙展示了他的作品。\n",
    "他有一個很好的網站（實際上是一本書） http://neuralnetworksanddeeplearning.com ，上面有這些美妙的JavaScript的控件，你可以在上面做操作。\n",
    "因為這是以前做的，以前我們一般用sigmoids激活函數。他演示了，如果你做足夠的矩陣乘法運算，然後用sigmoids處理（用ReLU也是完全一樣的），\n",
    "你可以創建出任意函數。這個線性函數和非線性函數的組合可以創建任意形狀的理論被稱作通用逼近定理。\n",
    "\n",
    "它說的是，如果你有一批線性函數和非線性函數，它們最終可以無限逼近任何函數。\n",
    "所以你只需要保證你有足夠大的或者足夠多的矩陣來做乘法運算。\n",
    "如果這個函數是由一批線性函數和非線性函數構成的，非線性函數可以是這些激活函數里的任何一個，\n",
    "如果它可以逼近任何函數，你需要做的就是找出這些做乘法的權重矩陣的值，這些矩陣相乘可以解決你要處理的問題。\n",
    "我們已經知道了怎樣找到參數的值。我們可以用梯度下降。就是這樣。\n",
    "\n",
    "我發現最難向學生們解釋的事情是：我們現在已經學完了。人們總是在課後來問我“其餘的是什麼，請解釋下深度學習的其餘的內容”。\n",
    "但是，沒有其餘的了。我們有一個函數可以接收像素或者其他的東西，我們用一些矩陣和輸入值相乘，把負值替換成0，\n",
    "我們再用另一個矩陣乘以它，把負值替換成0，多做幾次。我們看看它裡我們的目標有多近，然後按照梯度下降方法，用導數更新參數，多做幾次。\n",
    "最終，我們得到了可以分類電影評論或者可以識別布偶貓（ragdoll cat）的程序。就是這樣。\n",
    "\n",
    "這很難直觀地理解的原因是，我們講的矩陣是有上億個參數的（把所有的加起來）。它們是非常大的矩陣。\n",
    "對於多次用一個線性模型乘以一些東西，把負值替換成零這樣一個操作能做些什麼，你的直覺處理不了。你只能根據經驗來接受這個現實：這樣的操作很有效。\n",
    "\n",
    "在課程的第二部分，我們會從頭開始實現這些。但是提前講下，你會發現它們就是5行代碼。\n",
    "就是一個for循環，裡面運行t = x @ w1 , t2 = max(t, 0) , 再用一個for循環執行所有的矩陣，最後計算損失函數。\n",
    "當然，我們不會自己計算梯度，因為PyTorch為我們做了這些。就是這樣。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"提問: 有一個關於分詞的問題。我比較好奇分詞是怎樣做到處理詞組的，比如說San Francisco \n",
    "\n",
    "怎樣對San Francisco這樣的東西做分詞。 San Francisco包含兩個token 就是San一個而Francisco一個。就是這樣。這就是怎樣對 San Francisco做分詞。\n",
    "這個問題可能是做過傳統NLP的人提的，他們經常要用叫n-grams的東西。 N-rams是基於線性模型計算像San Francisco這樣的特定的文本字符串出現多少次。\n",
    "當n等於2時，n-grams就是bi-gram 。使用深度學習，我們不用再考慮這個，這很酷。像很多其它東西一樣，有了深度學習後，很多複雜的特徵工程用不上了。\n",
    "使用深度學習，每個token只是一個單詞（對you're這種實際上包含兩個詞的情況，你把它分成兩個單詞），\n",
    "然後我們要做的就是讓深度學習模型找出組合單詞的最好方法。現在，當我們說讓深度學習模型找出它來的時候，\n",
    "我們指的當然就是使用梯度下降找出能給出正確答案的權重矩陣。沒有其他的內容。\n",
    "\n",
    "另外，有些小技巧。在後半部分，我們會學習針對圖像模型的技巧，使用卷積，讓它成為CNN，針對語言模型的技巧是使用遞歸模型或者叫RNN。\n",
    "和剛才講的相比較，這都是次要的技巧。使用RNN，它可以學到當San和Francisco這兩個詞在一起時，會有不同的含義。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"提問: 一些衛星圖有4個通道。怎樣用預訓練模型處理4通道的數據或者2通道的數據？\n",
    "\n",
    "我想這是我們要嘗試並集成到fastai裡的東西。希望你們看到這個課程視頻時，會有做到這個的簡單方方法。\n",
    "預訓練的ImageNet模型接收紅綠藍像素。如果你只有兩個通道，你可以做一些事情，基本上就是多構造一個通道。\n",
    "可以讓這個通道裡的值都是0，或者是另外兩個通道的平均值。你可以使用普通的PyTorch運算來創建這樣一個通道。\n",
    "你可以提前在循環裡構造，保存一個三通道的版本，也可以根據需要創建一個定制的數據集。\n",
    "\n",
    "對於4通道的情況，你可能不希望捨棄第四個通道。\n",
    "所以你需要修改模型，在後面幾節課裡，我們會知道怎樣做。\n",
    "基本上是對於初始權重矩陣（權重矩陣是不准確的，應該叫權重張量weight tensors，因為有多個維度），\n",
    "它的一個軸上要有三個slice（切片），我們會用0或者隨機數初始化它們。簡單講就是這樣，但是要理解究竟這是什麼意思，我們還要再多花兩節課。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "使用和單標籤分類相同的方法，我們可以做這些事情，這很酷：\n",
    "\n",
    "做多標籤分類，\n",
    "比如處理planet數據集\n",
    "圖像分割\n",
    "各種圖像回歸\n",
    "NLP分類很多其他的\n",
    "\n",
    "每個任務裡，我們實際上做的都是：\n",
    "\n",
    "梯度下降\n",
    "非線性處理\n",
    "\n",
    "通用逼近定理告訴我們，它能幾乎無限逼近任何給定的函數，比如這些：\n",
    "\n",
    "把說話的聲音轉化成這個人說的內容把日語的句子轉換成英語的句子把一個狗的圖片轉換成一段描述狗的文字\n",
    "\n",
    "這些都是我們可以用這個方法學習的數學函數。\n",
    "\n",
    "比如多標籤分類、圖像回歸、圖像分割，或者其他類型的東西，試試你是不是能解決這個問題。\n",
    "你可能會發現最難的部分是創建data bunch，所以你需要深入學習data block API，學會怎樣用你的數據創建出data bunch。\n",
    "做些練習，你就會很擅長了。這不是一個很大的API，只有幾個部分。要添加你自己的方法也很容易。如果在嘗試時遇到了問題，就在論壇上提問。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
